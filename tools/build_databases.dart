#!/usr/bin/env dart
// æ•°æ®åº“æ‰“åŒ…å·¥å…·
// å°†ç¿»è¯‘å’Œå…±ç° CSV æ•°æ®æ‰“åŒ…ä¸ºé¢„æ„å»ºçš„ SQLite æ•°æ®åº“
//
// ä½¿ç”¨æ–¹æ³•:
//   dart tools/build_databases.dart
//
// è¾“å‡º:
//   assets/databases/translation.db
//   assets/databases/cooccurrence.db

import 'dart:io';
import 'package:sqflite_common_ffi/sqflite_ffi.dart';
import 'package:path/path.dart' as p;

// æ•°æ®åº“å¤§å°é™åˆ¶: 100MB
const int _maxDatabaseSize = 100 * 1024 * 1024;

// æ‰¹æ¬¡å¤§å°
const int _batchSize = 10000;

/// æ„å»ºç¿»è¯‘æ•°æ®åº“
Future<void> buildTranslationDatabase() async {
  print('ğŸ“¦ Building translation database...');

  const csvPath = 'assets/translations/hf_danbooru_tags.csv';
  final outputDir = Directory('assets/databases');
  final outputPath = p.join(outputDir.path, 'translation.db');

  if (!await File(csvPath).exists()) {
    print('  âŒ CSV not found: $csvPath');
    return;
  }

  await outputDir.create(recursive: true);

  // åˆ é™¤æ—§æ•°æ®åº“
  final oldDb = File(outputPath);
  if (await oldDb.exists()) {
    await oldDb.delete();
    print('  ğŸ—‘ï¸  Deleted old database');
  }

  // åˆ›å»ºæ–°æ•°æ®åº“
  final db = await databaseFactoryFfi.openDatabase(
    outputPath,
    options: OpenDatabaseOptions(
      version: 1,
      onCreate: (db, version) async {
        // æ ‡ç­¾è¡¨
        await db.execute('''
          CREATE TABLE tags (
            id INTEGER PRIMARY KEY,
            name TEXT NOT NULL UNIQUE,
            type INTEGER NOT NULL DEFAULT 0,
            count INTEGER NOT NULL DEFAULT 0
          )
        ''');

        // ç¿»è¯‘è¡¨
        await db.execute('''
          CREATE TABLE translations (
            tag_id INTEGER NOT NULL,
            language TEXT NOT NULL,
            translation TEXT NOT NULL,
            PRIMARY KEY (tag_id, language),
            FOREIGN KEY (tag_id) REFERENCES tags(id)
          )
        ''');

        // ç´¢å¼•
        await db.execute('CREATE INDEX idx_tags_name ON tags(name)');
        await db.execute('CREATE INDEX idx_tags_type ON tags(type)');
        await db.execute(
          'CREATE INDEX idx_translations_lang ON translations(language)',
        );

        print('  âœ… Tables created');
      },
    ),
  );

  try {
    // è§£æ CSV
    print('  ğŸ“– Reading CSV...');
    final content = await File(csvPath).readAsString();
    final lines = content.split('\n');

    print('  ğŸ“ Total lines: ${lines.length}');

    var importedTags = 0;
    var importedTranslations = 0;
    var currentTagId = 1;

    // ä½¿ç”¨äº‹åŠ¡æ‰¹é‡å¯¼å…¥
    await db.transaction((txn) async {
      final tagBatch = <Map<String, dynamic>>[];
      final translationBatch = <Map<String, dynamic>>[];

      for (var i = 1; i < lines.length; i++) {
        // è·³è¿‡è¡¨å¤´
        final line = lines[i].trim();
        if (line.isEmpty) continue;

        final parts = _parseCsvLine(line);
        if (parts.length < 4) continue;

        final name = parts[0].toLowerCase().trim();
        final type = int.tryParse(parts[1]) ?? 0;
        final count = int.tryParse(parts[2]) ?? 0;
        final cnTranslation = parts[3].trim();

        if (name.isEmpty) continue;

        // æ·»åŠ æ ‡ç­¾
        tagBatch.add({
          'id': currentTagId,
          'name': name,
          'type': type,
          'count': count,
        });

        // æ·»åŠ ä¸­æ–‡ç¿»è¯‘
        if (cnTranslation.isNotEmpty) {
          translationBatch.add({
            'tag_id': currentTagId,
            'language': 'zh',
            'translation': cnTranslation,
          });
        }

        currentTagId++;

        // æ‰¹é‡æäº¤
        if (tagBatch.length >= _batchSize) {
          await _insertBatch(txn, 'tags', tagBatch);
          await _insertBatch(txn, 'translations', translationBatch);
          importedTags += tagBatch.length;
          importedTranslations += translationBatch.length;
          tagBatch.clear();
          translationBatch.clear();

          if (importedTags % 50000 == 0) {
            print('    Imported $importedTags tags...');
          }
        }
      }

      // æäº¤å‰©ä½™æ•°æ®
      if (tagBatch.isNotEmpty) {
        await _insertBatch(txn, 'tags', tagBatch);
        await _insertBatch(txn, 'translations', translationBatch);
        importedTags += tagBatch.length;
        importedTranslations += translationBatch.length;
      }
    });

    print(
      '  âœ… Imported $importedTags tags, $importedTranslations translations',
    );

    // éªŒè¯æ•°æ®åº“å¤§å°
    final dbFile = File(outputPath);
    final size = await dbFile.length();
    print('  ğŸ“Š Database size: ${_formatFileSize(size)}');

    _checkSizeWarning(size, 'Translation');

    print('  âœ… Translation database built: $outputPath');
  } finally {
    await db.close();
  }
}

/// æ„å»ºå…±ç°æ•°æ®åº“
Future<void> buildCooccurrenceDatabase() async {
  print('ğŸ“¦ Building cooccurrence database...');

  const csvPath = 'assets/translations/hf_danbooru_cooccurrence.csv';
  final outputDir = Directory('assets/databases');
  final outputPath = p.join(outputDir.path, 'cooccurrence.db');

  if (!await File(csvPath).exists()) {
    print('  âŒ CSV not found: $csvPath');
    return;
  }

  await outputDir.create(recursive: true);

  // åˆ é™¤æ—§æ•°æ®åº“
  final oldDb = File(outputPath);
  if (await oldDb.exists()) {
    await oldDb.delete();
    print('  ğŸ—‘ï¸  Deleted old database');
  }

  // åˆ›å»ºæ–°æ•°æ®åº“
  final db = await databaseFactoryFfi.openDatabase(
    outputPath,
    options: OpenDatabaseOptions(
      version: 1,
      onCreate: (db, version) async {
        await db.execute('''
          CREATE TABLE cooccurrences (
            tag1 TEXT NOT NULL,
            tag2 TEXT NOT NULL,
            count INTEGER NOT NULL DEFAULT 0,
            cooccurrence_score REAL NOT NULL DEFAULT 0.0,
            PRIMARY KEY (tag1, tag2)
          )
        ''');

        // ç´¢å¼•
        await db.execute('''
          CREATE INDEX idx_cooccurrences_tag1_count 
          ON cooccurrences(tag1, count DESC, tag2)
        ''');

        print('  âœ… Table created');
      },
    ),
  );

  try {
    // è§£æ CSV
    print('  ğŸ“– Reading CSV...');
    final content = await File(csvPath).readAsString();
    final lines = content.split('\n');

    print('  ğŸ“ Total lines: ${lines.length}');

    var importedCount = 0;

    // ä½¿ç”¨äº‹åŠ¡æ‰¹é‡å¯¼å…¥
    await db.transaction((txn) async {
      final batch = <Map<String, dynamic>>[];

      for (var i = 1; i < lines.length; i++) {
        // è·³è¿‡è¡¨å¤´
        final line = lines[i].trim();
        if (line.isEmpty) continue;

        final parts = line.split(',');
        if (parts.length < 3) continue;

        final tag1 = parts[0].trim().toLowerCase();
        final tag2 = parts[1].trim().toLowerCase();
        final count = double.tryParse(parts[2].trim())?.toInt() ?? 0;

        if (tag1.isEmpty || tag2.isEmpty || count <= 0) continue;

        batch.add({
          'tag1': tag1,
          'tag2': tag2,
          'count': count,
          'cooccurrence_score': 0.0,
        });

        // æ‰¹é‡æäº¤
        if (batch.length >= _batchSize) {
          await _insertBatch(txn, 'cooccurrences', batch);
          importedCount += batch.length;
          batch.clear();

          if (importedCount % 100000 == 0) {
            print('    Imported $importedCount records...');
          }
        }
      }

      // æäº¤å‰©ä½™æ•°æ®
      if (batch.isNotEmpty) {
        await _insertBatch(txn, 'cooccurrences', batch);
        importedCount += batch.length;
      }
    });

    print('  âœ… Imported $importedCount cooccurrence records');

    // éªŒè¯æ•°æ®åº“å¤§å°
    final dbFile = File(outputPath);
    final size = await dbFile.length();
    print('  ğŸ“Š Database size: ${_formatFileSize(size)}');

    _checkSizeWarning(size, 'Cooccurrence');

    print('  âœ… Cooccurrence database built: $outputPath');
  } finally {
    await db.close();
  }
}

/// æ£€æŸ¥æ•°æ®åº“å¤§å°å¹¶è¾“å‡ºè­¦å‘Š
void _checkSizeWarning(int size, String name) {
  if (size > _maxDatabaseSize) {
    print('  âš ï¸  WARNING: $name database exceeds 100MB limit!');
  }
}

/// æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
String _formatFileSize(int bytes) {
  final mb = bytes / (1024 * 1024);
  return '${mb.toStringAsFixed(2)} MB';
}

/// æ‰¹é‡æ’å…¥è¾…åŠ©å‡½æ•°
Future<void> _insertBatch(
  Transaction txn,
  String table,
  List<Map<String, dynamic>> records,
) async {
  if (records.isEmpty) return;

  final columns = records.first.keys.toList();
  final placeholders = records.map((record) {
    return '(${columns.map((_) => '?').join(', ')})';
  }).join(', ');

  final values = <dynamic>[];
  for (final record in records) {
    for (final col in columns) {
      values.add(record[col]);
    }
  }

  final sql = 'INSERT INTO $table (${columns.join(', ')}) VALUES $placeholders';
  await txn.execute(sql, values);
}

/// è§£æ CSV è¡Œï¼ˆå¤„ç†å¼•å·ï¼‰
List<String> _parseCsvLine(String line) {
  final result = <String>[];
  final buffer = StringBuffer();
  var inQuotes = false;

  for (var i = 0; i < line.length; i++) {
    final char = line[i];

    if (char == '"') {
      if (inQuotes && i + 1 < line.length && line[i + 1] == '"') {
        // è½¬ä¹‰å¼•å·
        buffer.write('"');
        i++; // è·³è¿‡ä¸‹ä¸€ä¸ªå¼•å·
      } else {
        inQuotes = !inQuotes;
      }
    } else if (char == ',' && !inQuotes) {
      result.add(buffer.toString().trim());
      buffer.clear();
    } else {
      buffer.write(char);
    }
  }

  result.add(buffer.toString().trim());
  return result;
}

/// ä¸»å‡½æ•°
Future<void> main() async {
  print('ğŸ”§ Database Build Tool');
  print('');

  // åˆå§‹åŒ– FFI
  sqfliteFfiInit();
  databaseFactory = databaseFactoryFfi;

  final stopwatch = Stopwatch()..start();

  try {
    await buildTranslationDatabase();
    print('');
    await buildCooccurrenceDatabase();

    stopwatch.stop();
    print('');
    print('âœ¨ All databases built in ${stopwatch.elapsedMilliseconds}ms');
    print('');
    print('ğŸ“ Output location: assets/databases/');
    print('   - translation.db');
    print('   - cooccurrence.db');
  } catch (e, stack) {
    print('');
    print('âŒ Build failed: $e');
    print(stack);
    exit(1);
  }
}
